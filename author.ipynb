{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19574</td>\n",
       "      <td>id17718</td>\n",
       "      <td>I could have fancied, while I looked at it, th...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19575</td>\n",
       "      <td>id08973</td>\n",
       "      <td>The lids clenched themselves together as if in...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19576</td>\n",
       "      <td>id05267</td>\n",
       "      <td>Mais il faut agir that is to say, a Frenchman ...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19577</td>\n",
       "      <td>id17513</td>\n",
       "      <td>For an item of news like this, it strikes us i...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19578</td>\n",
       "      <td>id00393</td>\n",
       "      <td>He laid a gnarled claw on my shoulder, and it ...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19579 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text author\n",
       "0      id26305  This process, however, afforded me no means of...    EAP\n",
       "1      id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2      id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3      id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4      id12958  Finding nothing else, not even gold, the Super...    HPL\n",
       "...        ...                                                ...    ...\n",
       "19574  id17718  I could have fancied, while I looked at it, th...    EAP\n",
       "19575  id08973  The lids clenched themselves together as if in...    EAP\n",
       "19576  id05267  Mais il faut agir that is to say, a Frenchman ...    EAP\n",
       "19577  id17513  For an item of news like this, it strikes us i...    EAP\n",
       "19578  id00393  He laid a gnarled claw on my shoulder, and it ...    HPL\n",
       "\n",
       "[19579 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "authors_ds=pd.read_csv('Authors_dataset.csv')\n",
    "authors_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19574</td>\n",
       "      <td>id17718</td>\n",
       "      <td>I could have fancied, while I looked at it, th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19575</td>\n",
       "      <td>id08973</td>\n",
       "      <td>The lids clenched themselves together as if in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19576</td>\n",
       "      <td>id05267</td>\n",
       "      <td>Mais il faut agir that is to say, a Frenchman ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19577</td>\n",
       "      <td>id17513</td>\n",
       "      <td>For an item of news like this, it strikes us i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19578</td>\n",
       "      <td>id00393</td>\n",
       "      <td>He laid a gnarled claw on my shoulder, and it ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19579 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text  author\n",
       "0      id26305  This process, however, afforded me no means of...       1\n",
       "1      id17569  It never once occurred to me that the fumbling...       0\n",
       "2      id11008  In his left hand was a gold snuff box, from wh...       1\n",
       "3      id27763  How lovely is spring As we looked from Windsor...       2\n",
       "4      id12958  Finding nothing else, not even gold, the Super...       0\n",
       "...        ...                                                ...     ...\n",
       "19574  id17718  I could have fancied, while I looked at it, th...       1\n",
       "19575  id08973  The lids clenched themselves together as if in...       1\n",
       "19576  id05267  Mais il faut agir that is to say, a Frenchman ...       1\n",
       "19577  id17513  For an item of news like this, it strikes us i...       1\n",
       "19578  id00393  He laid a gnarled claw on my shoulder, and it ...       0\n",
       "\n",
       "[19579 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "authors_ds['author'].replace('EAP',1,inplace=True)\n",
    "authors_ds['author'].replace('HPL',0,inplace=True)\n",
    "authors_ds['author'].replace('MWS',2,inplace=True)       \n",
    "authors_ds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=authors_ds['author']\n",
    "authors_ds.drop(columns='author',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15663, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(authors_ds,y,test_size=0.2,random_state=43) \n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7333     kuran awak moment beheld citi yet knew brief g...\n",
       "2108     huge stone beam fall moment decay roof gave ev...\n",
       "17667    draught contrari move uniqu littl variat proba...\n",
       "8230     fool two mr rumgudgeon matter stand thu earth ...\n",
       "17218                              shall go alon accompani\n",
       "                               ...                        \n",
       "11198            yet pretend account mood particular event\n",
       "9847                     needless say felt inexpress alarm\n",
       "3763     recurr sheet lightn illum tumbl ground remain ...\n",
       "13789    england seat far north turbid sea visit dream ...\n",
       "1536     yet effect purpos could discern within precinc...\n",
       "Name: Cleaned_text, Length: 3916, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tokenize import tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tokenizer= RegexpTokenizer(r'\\w+')\n",
    "lemmatizer= WordNetLemmatizer()\n",
    "stemmer= PorterStemmer()\n",
    "\n",
    "\n",
    "\n",
    "def preprocessing(texts):\n",
    "    final_tokens=' '\n",
    "    tokens=tokenizer.tokenize(texts)\n",
    "         #print('Tokens:',tokens)\n",
    "    pure_tokens=[token.lower() for token in tokens if token.lower() not in stopwords.words('english')]\n",
    "    stemmed_tokens=[stemmer.stem(pure_token) for pure_token in pure_tokens]\n",
    "    final_tokens=final_tokens.join(stemmed_tokens)\n",
    "    return final_tokens\n",
    "     \n",
    "preprocessing('I was eating breakfast when you were playing')\n",
    "x_train['Cleaned_text']=x_train['text'].apply(preprocessing)\n",
    "x_train['Cleaned_text']\n",
    "\n",
    "x_test['Cleaned_text']=x_test['text'].apply(preprocessing)\n",
    "x_test['Cleaned_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>Cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12944</td>\n",
       "      <td>id05324</td>\n",
       "      <td>After dinner, however, when you have sufficien...</td>\n",
       "      <td>dinner howev suffici recov fatigu ride happi t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12676</td>\n",
       "      <td>id26471</td>\n",
       "      <td>The greater part of the fearful night had worn...</td>\n",
       "      <td>greater part fear night worn away dead stir vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3569</td>\n",
       "      <td>id27195</td>\n",
       "      <td>There was, however, something he wanted in emb...</td>\n",
       "      <td>howev someth want embattl flander order secur ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9448</td>\n",
       "      <td>id04173</td>\n",
       "      <td>Its contents were of the most startling nature...</td>\n",
       "      <td>content startl natur perus confirm gravest app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17636</td>\n",
       "      <td>id24471</td>\n",
       "      <td>No one knew, no one could imagine; no one not ...</td>\n",
       "      <td>one knew one could imagin one even burgomast m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5307</td>\n",
       "      <td>id04712</td>\n",
       "      <td>\"And, all at once, the moon arose through the ...</td>\n",
       "      <td>moon aros thin ghastli mist crimson color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18448</td>\n",
       "      <td>id09723</td>\n",
       "      <td>The ceiling, of gloomy looking oak, was excess...</td>\n",
       "      <td>ceil gloomi look oak excess lofti vault elabor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7985</td>\n",
       "      <td>id18983</td>\n",
       "      <td>Have any of you, my readers, observed the ruin...</td>\n",
       "      <td>reader observ ruin anthil immedi destruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18687</td>\n",
       "      <td>id03539</td>\n",
       "      <td>This would naturally have been the case.</td>\n",
       "      <td>would natur case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14148</td>\n",
       "      <td>id24417</td>\n",
       "      <td>\"Oh, shocking\" groaned the Earl.</td>\n",
       "      <td>oh shock groan earl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15663 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text  \\\n",
       "12944  id05324  After dinner, however, when you have sufficien...   \n",
       "12676  id26471  The greater part of the fearful night had worn...   \n",
       "3569   id27195  There was, however, something he wanted in emb...   \n",
       "9448   id04173  Its contents were of the most startling nature...   \n",
       "17636  id24471  No one knew, no one could imagine; no one not ...   \n",
       "...        ...                                                ...   \n",
       "5307   id04712  \"And, all at once, the moon arose through the ...   \n",
       "18448  id09723  The ceiling, of gloomy looking oak, was excess...   \n",
       "7985   id18983  Have any of you, my readers, observed the ruin...   \n",
       "18687  id03539           This would naturally have been the case.   \n",
       "14148  id24417                   \"Oh, shocking\" groaned the Earl.   \n",
       "\n",
       "                                            Cleaned_text  \n",
       "12944  dinner howev suffici recov fatigu ride happi t...  \n",
       "12676  greater part fear night worn away dead stir vi...  \n",
       "3569   howev someth want embattl flander order secur ...  \n",
       "9448   content startl natur perus confirm gravest app...  \n",
       "17636  one knew one could imagin one even burgomast m...  \n",
       "...                                                  ...  \n",
       "5307           moon aros thin ghastli mist crimson color  \n",
       "18448  ceil gloomi look oak excess lofti vault elabor...  \n",
       "7985           reader observ ruin anthil immedi destruct  \n",
       "18687                                   would natur case  \n",
       "14148                                oh shock groan earl  \n",
       "\n",
       "[15663 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer=TfidfVectorizer(stop_words='english',use_idf=True)\n",
    "\n",
    "vectorizer.fit(x_train['Cleaned_text'])\n",
    "x_train_Tfidf=vectorizer.transform(x_train['Cleaned_text'])\n",
    "x_test_Tfidf=vectorizer.transform(x_test['Cleaned_text'])\n",
    "\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score,roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "clf= MultinomialNB().fit(x_train_Tfidf.toarray(),y_train)\n",
    "# clf.score(x_train_Tfidf.toarray(),y_train)\n",
    "    \n",
    "# test_review='that product was its absolute best and i loved using every feature of it'\n",
    "\n",
    "# x_test['Cleaned_text']=x_\n",
    "\n",
    "y_pred=clf.predict(x_test_Tfidf.toarray())\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08961293, 0.6162028 , 0.762852  , ..., 0.09360948, 0.22979486,\n",
       "       0.5560326 ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba_pred=clf.predict_proba(x_test_Tfidf.toarray())[::,1]\n",
    "y_proba_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8117977528089888"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report\n",
    "Accuracy_Score = accuracy_score(y_test,y_pred)\n",
    "Accuracy_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg=LogisticRegression()\n",
    "logreg.fit(x_train_Tfidf,y_train)\n",
    "y_pred=logreg.predict(x_test_Tfidf)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 847,  211,   76],\n",
       "       [  94, 1375,   98],\n",
       "       [  75,  216,  924]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparisons_df=pd.DataFrame({'Actuals':y_test,'predictions':y_pred})\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,precision_score,recall_score,f1_score\n",
    "\n",
    "confusion_matrix(y_test,y_pred)\n",
    "\n",
    "# recall_score(y_test,y_pred)\n",
    "# precision_score(y_test,y_pred)\n",
    "\n",
    "# f1_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-983344e3089f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# precision_score(y_test,y_pred)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# f1_score(y_test,y_pred)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\SEMONA\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mrecall_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1787\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'recall'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1788\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1789\u001b[1;33m                                                  zero_division=zero_division)\n\u001b[0m\u001b[0;32m   1790\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\SEMONA\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1482\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1483\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[1;32m-> 1484\u001b[1;33m                                     pos_label)\n\u001b[0m\u001b[0;32m   1485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1486\u001b[0m     \u001b[1;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\SEMONA\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1314\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[0;32m   1315\u001b[0m                              \u001b[1;34m\"choose another average setting, one of %r.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1316\u001b[1;33m                              % (y_type, average_options))\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "\n",
    "# precision_score(y_test,y_pred)\n",
    "\n",
    "# f1_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.75      0.79      1134\n",
      "           1       0.76      0.88      0.82      1567\n",
      "           2       0.84      0.76      0.80      1215\n",
      "\n",
      "    accuracy                           0.80      3916\n",
      "   macro avg       0.81      0.79      0.80      3916\n",
      "weighted avg       0.81      0.80      0.80      3916\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "visualizer =classification_report(y_test,y_pred)\n",
    "print(visualizer) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
